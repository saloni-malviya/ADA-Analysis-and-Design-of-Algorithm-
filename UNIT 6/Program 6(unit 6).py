# Develop a local search algorithm for the Maximum Cut Problem, and compare its performance to that of a randomized algorithm on a set of random graphs.

import networkx as nx
import random

def maximum_cut_local_search(G):
    # Initialize a random initial partition
    partition = {node: random.choice([0, 1]) for node in G.nodes()}
    
    # Compute the initial cut weight
    cut_weight = sum(G.edges[u, v]['weight'] for u, v in G.edges() if partition[u] != partition[v])
    
    # Keep iterating until no further improvement can be made
    improved = True
    while improved:
        improved = False
        for node in G.nodes():
            # Try moving the node to the other partition
            new_partition = partition.copy()
            new_partition[node] = 1 - new_partition[node]
            new_cut_weight = sum(G.edges[u, v]['weight'] for u, v in G.edges() if new_partition[u] != new_partition[v])
            
            # Accept the move if it results in an improvement
            if new_cut_weight > cut_weight:
                partition = new_partition
                cut_weight = new_cut_weight
                improved = True
    
    # Return the final partition and cut weight
    return partition, cut_weight

# Compare its performance to that of a randomized algorithm on a set of random graphs.
"""
To evaluate the performance of this algorithm, 
we can generate a set of random graphs of varying sizes and densities,
and compare the running time and solution quality of the local search 
algorithm to that of a randomized algorithm that simply selects a random partition and
computes the cut weight. Here is an example implementation:

"""
import time

# Generate a set of random graphs
graphs = []
for n in [10, 20, 50, 100]:
    for p in [0.1, 0.2, 0.5]:
        G = nx.erdos_renyi_graph(n, p, seed=123)
        for u, v in G.edges():
            G[u][v]['weight'] = random.uniform(0, 1)
        graphs.append(G)

# Run the algorithms on each graph and record the results
results = []
for G in graphs:
    # Run the local search algorithm
    start_time = time.time()
    partition, cut_weight = maximum_cut_local_search(G)
    end_time = time.time()
    local_search_time = end_time - start_time
    
    # Run the randomized algorithm
    start_time = time.time()
    random_partition = {node: random.choice([0, 1]) for node in G.nodes()}
    random_cut_weight = sum(G.edges[u, v]['weight'] for u, v in G.edges() if random_partition[u] != random_partition[v])
    end_time = time.time()
    random_time = end_time - start_time
    
    # Record the results
    results.append({'n': G.number_of_nodes(),
                    'p': G.number_of_edges() / (G.number_of_nodes() * (G.number_of_nodes() - 1) / 2),
                    'local_search_time': local_search_time,
                    'local_search_cut_weight': cut_weight,
                    'random_time': random_time,